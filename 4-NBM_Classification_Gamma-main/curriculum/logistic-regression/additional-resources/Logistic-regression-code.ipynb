{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "# To edit this:\n",
    "# code $(jupyter --data-dir)/nbextensions/snippets/snippets.json\n",
    "\n",
    "# imports a library 'pandas', names it as 'pd'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# enables inline plots, without it plots don't show up in the notebook\n",
    "# %config InlineBackend.figure_format = 'svg'\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "mpl.rcParams['figure.dpi']= 300\n",
    "mpl.rcParams[\"figure.figsize\"] = (6,4.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "x = np.random.randn(100)\n",
    "x = np.sort(x)\n",
    "y = np.exp(x+np.random.randn(100)/3)\n",
    "\n",
    "plt.plot(x,y,'.')\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,np.log(y),'.')\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$\\log y$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,np.log(y),'.')\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$\\log\\ y$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.special import logit, expit,logsumexp\n",
    "np.random.seed(43)\n",
    "x = np.arange(30)\n",
    "p = expit((15-x)/5)\n",
    "y = np.random.binomial(1,p)\n",
    "\n",
    "plt.plot(x,y,'.')\n",
    "plt.plot(x,p,label=\"$\\mathbb{E}(y|x)$\")\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.yticks([0,1]);\n",
    "plt.legend();\n",
    "plt.scatter(15 - 5*logit(0.75),0.75,c='C1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(42)\n",
    "x = np.random.randn(100)\n",
    "x = np.sort(x)\n",
    "y = -x+np.random.randn(100)/3\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(x,y,'.')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Regression\" is about computing _conditional expectations_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "x = np.random.randn(100)\n",
    "x = np.sort(x)\n",
    "y = -x+np.random.randn(100)/3\n",
    "\n",
    "def linplot():\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.plot(x,y,'.')\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$y$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "x = np.random.randn(100)\n",
    "x = np.sort(x)\n",
    "y = -x+np.random.randn(100)/3\n",
    "\n",
    "plt.plot(x,y,'.')\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$');\n",
    "\n",
    "yt = np.linspace(np.min(y),np.max(y),100)\n",
    "\n",
    "x0 = 1.5\n",
    "xt = x0 - 0.2 * st.norm.pdf(yt,-x0,1/3)\n",
    "# plt.plot(x0+np.zeros_like(yt),yt,c='C1',alpha=0.2)\n",
    "# plt.plot(xt,yt);\n",
    "\n",
    "# xpts = np.array([-1.5,-0.5,0.5,1.5])\n",
    "# plt.scatter(xpts,-xpts,c='C1');\n",
    "ylimits = plt.ylim()\n",
    "plt.plot(x,-x,c='C1',label=\"$\\mathbb{E}(y|x)$\");\n",
    "plt.ylim(*ylimits)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y,'.')\n",
    "plt.plot(x,p,label=\"$P(y=1)$\")\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y,'.')\n",
    "plt.plot(x,p)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.scatter(15 - 5*logit(0.75),0.75,c='C1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-4,4)\n",
    "p = expit(x)\n",
    "plt.figure(figsize=[6.4,4.8])\n",
    "plt.plot(x,p);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[4.8,6.4])\n",
    "plt.plot(p,x)\n",
    "plt.xlabel('$p$')\n",
    "plt.ylabel('$x = $logit$(p)$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use cmap bwr or seismic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, metrics\n",
    "digits = datasets.load_digits(n_class=10)\n",
    "\n",
    "# The data that we are interested in is made of 8x8 images of digits, let's\n",
    "# have a look at the first 4 images, stored in the `images` attribute of the\n",
    "# dataset.  If we were working from image files, we could load them using\n",
    "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
    "# images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset.\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "plt.show()\n",
    "\n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits.data\n",
    "y = digits.target\n",
    "mask = np.isin(y,[1,3,8,9])\n",
    "X = X[mask,:]\n",
    "y = y[mask]\n",
    "\n",
    "n_samples, n_features = X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from http://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html\n",
    "def plot_embedding(X, title=None):\n",
    "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
    "    X = (X - x_min) / (x_max - x_min)\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    for i in range(X.shape[0]):\n",
    "        plt.text(X[i, 0], X[i, 1], str(y[i]),\n",
    "                 color=plt.cm.tab10(y[i]),\n",
    "                 fontdict={'weight': 'bold', 'size': 9})\n",
    "\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "X2 = X.copy()\n",
    "X2.flat[::X.shape[1] + 1] += 0.01  # Make X invertible\n",
    "X_lda = LinearDiscriminantAnalysis(n_components=5).fit_transform(X2, y)\n",
    "plot_embedding(X_lda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(multi_class='ovr',solver='lbfgs')\n",
    "lr.fit(X_lda, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlim,ylim = zip(np.min(X_lda,0),np.max(X_lda,0))\n",
    "\n",
    "xs = np.linspace(*xlim,500)\n",
    "ys = np.linspace(*ylim,500)\n",
    "xx,yy = np.meshgrid(xs,ys)\n",
    "probs = lr.decision_function(np.vstack([xx.ravel(),yy.ravel()]).T)\n",
    "preds = np.argmax(probs, 1)\n",
    "zz = preds.reshape(xx.shape)\n",
    "#plt.contourf(xx,yy,zz,alpha=0.3)\n",
    "p  = plt.contourf(xx,yy,zz,cmap=plt.cm.tab10,alpha=0.3)\n",
    "(np.mean(xx[zz==1]),np.mean(yy[zz==1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(np.sqrt(confusion_matrix(y,lr.predict(X_lda))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "princomps = pca.transform(data)\n",
    "plt.scatter(princomps[:,0],princomps[:,1],c=digits.target)\n",
    "digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,1),frameon=False)\n",
    "x = np.linspace(-4,4,100)\n",
    "plt.plot(x,expit(x));\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "for j in range(100):\n",
    "    μ = np.random.normal(size=3)\n",
    "    σ = np.abs(np.random.normal(size=3))\n",
    "    \n",
    "    x1 = np.random.normal(0,1,size=100)\n",
    "    x2 = np.random.normal(0,0.4,size=100)\n",
    "    x3 = np.random.normal(2,1,size=100)\n",
    "\n",
    "    x = np.hstack([x1,x2,x3])\n",
    "    s = np.argsort(x)\n",
    "    x = x[s].reshape(-1,1)\n",
    "    y = y = np.array([1]*100 + [2]*100 + [3]*100)[s]\n",
    "\n",
    "\n",
    "\n",
    "    softmax = LogisticRegression(solver='lbfgs',multi_class='multinomial')\n",
    "    softmax.fit(x,y)\n",
    "    plt.plot(x,x.dot(softmax.coef_.T));\n",
    "    # plt.ylim(0,1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truelogprobs(x,μ,σ):\n",
    "    x = x.reshape(-1,1)\n",
    "    μ = μ.reshape(1,-1)\n",
    "    σ = σ.reshape(1,-1)\n",
    "    logprobs = st.norm.logpdf(x,μ,σ)\n",
    "    logprobs -= logsumexp(logprobs,1).reshape(-1,1)\n",
    "    return logprobs\n",
    "\n",
    "def trueprobs(x,μ,σ):\n",
    "    x = x.reshape(-1,1)\n",
    "    μ = μ.reshape(1,-1)\n",
    "    σ = σ.reshape(1,-1)\n",
    "    probs = st.norm.pdf(x,μ,σ)\n",
    "    probs /= np.sum(probs,1).reshape(-1,1)\n",
    "    return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "ovr = LogisticRegression(C=1e100)\n",
    "softmax = LogisticRegression(C=1e100,solver='lbfgs',multi_class='multinomial')\n",
    "\n",
    "datapts = 100\n",
    "iters = 10000\n",
    "gridsize = 1000\n",
    "ovr_confusion = np.zeros([gridsize+1,gridsize+1])\n",
    "softmax_confusion = np.zeros([gridsize+1,gridsize+1])\n",
    "for j in range(iters):\n",
    "    # Make some fake data\n",
    "    μ = np.random.normal(size=3)\n",
    "    σ = np.abs(np.random.normal(size=3))\n",
    "    x = np.random.normal(μ.reshape(1,-1),σ.reshape(1,-1),size=(datapts,3))\n",
    "    x = np.hstack(x.T).reshape(-1,1)\n",
    "    y = np.array([0]*datapts+[1]*datapts+[2]*datapts)\n",
    "\n",
    "    # Determine ground truth\n",
    "    probs = trueprobs(x,μ,σ)\n",
    "    preds = np.argmax(probs,1)\n",
    "    maj = (gridsize*probs[range(probs.shape[0]),preds]).astype(int)\n",
    "    \n",
    "    # Fit both models\n",
    "    ovr.fit(x,y)\n",
    "    softmax.fit(x,y)\n",
    "\n",
    "    # Increment confusion matrices\n",
    "    ovr_maj = (gridsize*ovr.predict_proba(x)[range(probs.shape[0]),preds]).astype(int)   \n",
    "    ovr_confusion[maj,ovr_maj] += 1\n",
    "\n",
    "    softmax_maj = (gridsize*softmax.predict_proba(x)[range(probs.shape[0]),preds]).astype(int)   \n",
    "    softmax_confusion[maj,softmax_maj] += 1\n",
    "\n",
    "    \n",
    "#     plt.plot(maj, ovr.predict_proba(x)[range(probs.shape[0]),preds],'.',c='C0',alpha=0.01,markersize=1)\n",
    "#     plt.plot(maj, softmax.predict_proba(x)[range(probs.shape[0]),preds],'.',c='C1',alpha=0.01,markersize=1)\n",
    "#     plt.plot(probs, ovr.predict_proba(x),c='C0',alpha=0.01)\n",
    "#     plt.plot(probs, softmax.predict_proba(x),c='C1',alpha=0.01)\n",
    "#     kl_ovr[j] = np.mean(kl_divergence(trueprobs(x,μ,σ).T,ovr.predict_proba(x).T,base=2))\n",
    "#     kl_softmax[j] = np.mean(kl_divergence(trueprobs(x,μ,σ).T,softmax.predict_proba(x).T,base=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findqindex(v,q=[0.05,0.5,0.95]):\n",
    "    c = np.cumsum(v)\n",
    "    return np.searchsorted(c, np.array(q) * c[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findqindex([5,2,6,3,6,7,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.apply_along_axis(findqindex,1,softmax_confusion)/gridsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (m,color,name) in [(softmax_confusion,'C0','softmax'),(ovr_confusion,'C1','one-vs-rest')]:\n",
    "    qs = np.apply_along_axis(findqindex,1,m)/gridsize\n",
    "    qs = qs[np.sum(qs,1)>0]\n",
    "    xs = np.linspace(0.33,1,qs.shape[0])\n",
    "    plt.plot(xs,qs[:,1],c=color,label=name)\n",
    "    plt.plot(xs,qs[:,0],c=color,lw=0.2)\n",
    "    plt.plot(xs,qs[:,2],c=color,lw=0.2)\n",
    "    plt.fill_between(xs,qs[:,0],qs[:,2],color=color,alpha=0.1)\n",
    "plt.plot([0.33,1],[0.33,1],c='red',linestyle='--',lw=0.5,label='ground truth')\n",
    "plt.legend()\n",
    "plt.xlabel(\"True majority-class probability\")\n",
    "plt.ylabel('Estimated probability');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = st.norm.pdf(x,μ,σ)\n",
    "preds = np.argmax(probs,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(kl_softmax, kl_ovr,'.',alpha=0.2)\n",
    "plt.xlabel('Softmax')\n",
    "plt.ylabel('One-vs-rest')\n",
    "m=np.max(kl_softmax)\n",
    "plt.plot([0,m],[0,m],c='red');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "x1 = np.random.normal(0,1,size=100)\n",
    "x2 = np.random.normal(0,0.4,size=100)\n",
    "x3 = np.random.normal(2,1,size=100)\n",
    "\n",
    "x = np.hstack([x1,x2,x3])\n",
    "s = np.argsort(x)\n",
    "x = x[s].reshape(-1,1)\n",
    "y = y[s]\n",
    "\n",
    "\n",
    "y = np.array([1]*100 + [2]*100 + [3]*100)\n",
    "ovr = LogisticRegression()\n",
    "ovr.fit(x,y)\n",
    "plt.plot(x,x.dot(ovr.coef_.T))\n",
    "# plt.plot(x,ovr.predict_proba(x))\n",
    "# plt.ylim(0,1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metis",
   "language": "python",
   "name": "metis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
